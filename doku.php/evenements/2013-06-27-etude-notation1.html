<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Transitional//EN"
 "http://www.w3.org/TR/xhtml1/DTD/xhtml1-transitional.dtd">
<html xmlns="http://www.w3.org/1999/xhtml" xml:lang="fr"
 lang="fr" dir="ltr">

<!-- Mirrored from notation.afim-asso.org/doku.php/evenements/2013-06-27-etude-notation1 by HTTrack Website Copier/3.x [XR&CO'2014], Mon, 19 Oct 2020 07:52:38 GMT -->
<!-- Added by HTTrack --><meta http-equiv="content-type" content="text/html;charset=utf-8" /><!-- /Added by HTTrack -->
<head>
  <meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
  <title>
    evenements:2013-06-27-etude-notation1 – Les nouveaux espaces de la notation musicale  </title>

  <meta name="generator" content="DokuWiki"/>
<meta name="robots" content="index,follow"/>
<meta name="keywords" content="evenements,2013-06-27-etude-notation1"/>
<link rel="start" href="../../index.html"/>
<link rel="manifest" href="../../lib/exe/manifest.php"/>
<link rel="alternate" type="application/rss+xml" title="Derniers changements" href="../../feed.php"/>
<link rel="alternate" type="application/rss+xml" title="Catégorie courante" href="../../feedf001.php?mode=list&amp;ns=evenements"/>
<link rel="alternate" type="text/html" title="HTML brut" href="2013-06-27-etude-notation147cd.html?do=export_xhtml"/>
<link rel="canonical" href="2013-06-27-etude-notation1.html"/>
<link rel="stylesheet" type="text/css" href="../../lib/exe/cssc55d.css?t=A_Centered_Perspective&amp;tseed=22a5003533456f171a7552a81b2eda2d"/>
<!--[if gte IE 9]><!-->
<script type="text/javascript">/*<![CDATA[*/var NS='evenements';var JSINFO = {"id":"evenements:2013-06-27-etude-notation1","namespace":"evenements","ACT":"show","useHeadingNavigation":0,"useHeadingContent":0};
/*!]]>*/</script>
<script type="text/javascript" charset="utf-8" src="../../lib/exe/jquery1d4f.php?tseed=23f888679b4f1dc26eef34902aca964f"></script>
<script type="text/javascript" charset="utf-8" src="../../lib/exe/jsc55d.php?t=A_Centered_Perspective&amp;tseed=22a5003533456f171a7552a81b2eda2d"></script>
<!--<![endif]-->

  <link rel="shortcut icon" href="../../lib/tpl/A_Centered_Perspective/images/favicon.ico" />

  
</head>
<body class="dw-right">
<div class="headerinc">
Dieses Dokuwiki verwendet ein von <a href="http://www.anymorphic.com/">Anymorphic Webdesign</a> erstelltes Thema.
</div>


<div id="menubar" class="dokuwiki">   
   
		<a href="../start.html"  name="dokuwiki__top" accesskey="h" title="[ALT+H]" id="wikititle">Les nouveaux espaces de la notation musicale</a>				 
            <div class="action-menus">
        <div class="action-menu">
			<div class="action-menu-title unicode">
				⚙
			</div>
			<div class="action-menu-content">
          <a href="2013-06-27-etude-notation139b4.html?do=edit"  class="action source" accesskey="v" rel="nofollow" title="Afficher le texte source [V]">Afficher le texte source</a>			</div>
        </div>
        <div class="action-menu">
        <div class="action-menu-title unicode">
			⚒
		</div>
		<div class="action-menu-content"><a href="2013-06-27-etude-notation151ef.html?do=login&amp;sectok="  class="action login" rel="nofollow" title="S&#039;identifier">S'identifier</a></div>
        </div>
    </div>
    








</div>







<div id="wrapper" class="dokuwiki">

    	


    


      

    
    
    
              <div class="left-page">
 <div id="page">
<h2 class="sectionedit1" id="symposiumworkshop-music-notation-1">Symposium / Workshop Music Notation #1</h2>
<div class="level2">

<p>
<a href="../../lib/exe/detail.php/evenements/8524856986_ee9ed01bac_z647b.html?id=evenements%3A2013-06-27-etude-notation1" class="media" title="evenements:8524856986_ee9ed01bac_z.jpg"><img src="../../lib/exe/fetch.php/evenements/8524856986_ee9ed01bac_z.jpg_%3b" class="media" alt="" /></a>
</p>

<p>
Organization : AFIM/MINT-OMF
</p>

<p>
<strong>June 27, 2013 - 9:00-5:30PM</strong>
</p>
<pre class="code">Université Paris-Sorbonne 
Maison de la recherche
Room D040
26 rue Serpente 75006 Paris
(Métro Saint-Michel ou Odéon)</pre>

<p>
<strong>Presentation</strong>
</p>

<p>
The research group “<strong>New Fields of Music Notation</strong>” organizes a workshop in June 27, 2013 at the Paris-Sorbonne University in collaboration with the research group <a href="http://omf.paris-sorbonne.fr/presentationMINT" class="urlextern" title="http://omf.paris-sorbonne.fr/presentationMINT" rel="nofollow">Musicologie, Informatique et Nouvelles Technologies</a> (MINT). This session will provide an opportunity to make a state of art of recent research in the field of musical notation through creation and musical research.
</p>

<p>
Le groupe de travail de l&#039;AFIM <strong>Les nouveaux espaces de la notation musicale</strong> organise une session de travail le 27 juin 2013 à l&#039;Université Paris-Sorbonne en collaboration avec le groupe Musicologie, Informatique et Nouvelles Technologies (MINT). Cette session sera l&#039;occasion de faire un état de l&#039;art sur les recherches récentes dans le domaine de la notation musicale.
</p>

<p>
<strong>Programme</strong>
</p>

<p>
Programme détaillé : <a href="../../lib/exe/fetch.php/evenements/programme09.pdf_%3b" class="media mediafile mf_pdf" title="evenements:programme09.pdf (196.4 KB)">programme09.pdf</a>
</p>
<ul>
<li class="level1"><div class="li"> 9h00-9h15 Ouverture</div>
</li>
</ul>
<ul>
<li class="level1"><div class="li"> 9h15-9h45 - Alice Tacaille, Dang Nguyen Bac<br/>
<strong>Deux bases de données musicales avec développements musicxml : Carnet de Notes (analyse) et Neuma (CNRS - Bibliothèque numérique)</strong></div>
</li>
<li class="level1"><div class="li"> 9h45-10h15 - Clarisse Bardiot, Guillaume Marais<br/>
<strong>Rekall : un environnement open-source pour documenter, analyser les processus de création et simplifier la reprise des œuvres</strong></div>
</li>
<li class="level1"><div class="li"> 10h15-10h45 - Véronique Alexandre Journeau<br/>
<strong>Informatisation de la notation chinoise en tablature pour guqin</strong></div>
</li>
</ul>
<ul>
<li class="level1"><div class="li"> 10h45-11h00 Pause</div>
</li>
</ul>
<ul>
<li class="level1"><div class="li"> 11h00-11h30 - Mathieu Chailloux, Jérémie Garcia &amp; Carlos Agon<br/>
<strong>Vers des partitions interactives pour l’aide à la composition et à l’analyse musicale</strong></div>
</li>
<li class="level1"><div class="li"> 11h30-12h00 - Yannick Chapuis<br/>
<strong>La librairie OMXmulti pour OpenMusic un outil d&#039;aide à la précomposition musicale</strong></div>
</li>
<li class="level1"><div class="li"> 12h00-12h30 - José Echeveste, Thomas Coffy<br/>
<strong>The Antescofo musical notation: programming realtime musical interactivity</strong></div>
</li>
</ul>
<ul>
<li class="level1"><div class="li"> 12h30-14h00 Déjeuner</div>
</li>
</ul>
<ul>
<li class="level1"><div class="li"> 14h00-14h30 Marlon Schumacher<br/>
<strong>A Dictionary-Based Approach for the Notation of Musical Audio</strong></div>
</li>
<li class="level1"><div class="li"> 14h30-15h00 Jean-Louis Di Santo<br/>
<strong>L&#039;acousmoscribe</strong></div>
</li>
<li class="level1"><div class="li"> 15h00-15h30 Gabriel Shalom<br/>
<strong>Audiovisual Notation &amp; Transcription. Case Study : The Tosso Variations</strong></div>
</li>
</ul>
<ul>
<li class="level1"><div class="li"> 15h30-15h45 Pause</div>
</li>
</ul>
<ul>
<li class="level1"><div class="li"> 15h45-16h15 - Bertrand Merlier<br/>
<strong>Notation de lʼespace en musique électroacoustique : du geste au signe</strong></div>
</li>
<li class="level1"><div class="li"> 16h15-16h45 - Guillaume Jacquemin, Matthieu Ranc<br/>
<strong>Iannix 0.9 : Partition graphique interactive</strong></div>
</li>
<li class="level1"><div class="li"> 16h45-17h15 - Emile Ellberger<br/>
<strong>SSMN: A research project at the ICST (ZHdK)</strong></div>
</li>
</ul>
<ul>
<li class="level1"><div class="li"> 17h15-17h30 - Conclusion de la journée</div>
</li>
</ul>

<p>
<br/>

<br/>

</p>
<hr />

</div>

<h3 class="sectionedit2" id="resumes-des-interventions">Résumés des interventions</h3>
<div class="level3">

<p>
<a href="../../lib/exe/detail.php/evenements/2013-06-27-etude-notation1/neuma647b.html?id=evenements%3A2013-06-27-etude-notation1" class="media" title="evenements:2013-06-27-etude-notation1:neuma.jpeg"><img src="../../lib/exe/fetch.php/evenements/2013-06-27-etude-notation1/neuma1d84.jpeg_%3b?w=160&amp;tok=edc101" class="mediaright" alt="" width="160" /></a>
</p>

</div>

<h4 class="sectionedit3" id="deux-bases-de-donnees-musicales-avec-developpements-musicxmlcarnet-de-notes-analyse-et-neuma-cnrs-bibliotheque-numerique">Deux bases de données musicales avec développements musicxml : Carnet de Notes (analyse) et Neuma (CNRS - Bibliothèque numérique)</h4>
<div class="level4">

<p>
<br/>

<strong>Alice Tacaille (Université Paris-Sorbonne), Dang Nguyen Bac (ENS Lyon)</strong>
</p>

<p>
Carnet de Notes (PLM) et Neuma (CNRS) sont deux programmes de librairie musicale digitale. Ils sont fondés sur des corpus rares, que les usagers notent eux-mêmes en notation musicale pour leur usage personnel, pour l&#039;indexation ou pour la publication.  Le format dans lequel ils sont chargés (uploadés) , musicxml, permet des applications d&#039;analyse (PLM) ou d&#039;annotation, partage, création de métadonnées (Neuma) ouvertes à l&#039;expérimentation.
</p>
<hr />

</div>

<h4 class="sectionedit4" id="rekallun-environnement-open-source-pour-documenter-analyser-les-processus-de-creation-et-simplifier-la-reprise-des-oeuvres">Rekall : Un environnement open-source pour documenter, analyser les processus de création et simplifier la reprise des oeuvres</h4>
<div class="level4">

<p>
<br/>

<a href="../../lib/exe/detail.php/evenements/2013-06-27-etude-notation1/rekall647b.html?id=evenements%3A2013-06-27-etude-notation1" class="media" title="evenements:2013-06-27-etude-notation1:rekall.png"><img src="../../lib/exe/fetch.php/evenements/2013-06-27-etude-notation1/rekallbf12.png_%3b?w=300&amp;tok=e3cf41" class="mediaright" alt="" width="300" /></a>
<strong>Clarisse Bardiot (UVHC - CNRS), Guillaume Marais (Association Rekall)</strong>
</p>

<p>
Rekall est une réponse aux problématiques de documentation et de conservation des arts à composante technologique, ainsi qu’aux difficultés rencontrées par les artistes lors de la reprise d’un spectacle dont les technologies sont devenues obsolètes. En période de création, il permet de gagner du temps pour retrouver facilement les choix techniques et artistiques effectués d’une résidence à une autre.
</p>

<p>
À la fois clair et facile à prendre en main, Rekall permet de nombreux usages. Il est conçu pour :
</p>
<ul>
<li class="level1"><div class="li"> les régisseurs : prise de note rapide pendant les répétitions, mémorisation des différentes conduites techniques (son, lumière, vidéo, dispositifs technologiques), regroupement de tous les documents techniques ;</div>
</li>
<li class="level1"><div class="li"> les artistes : regroupement et sauvegarde des différents éléments du spectacle (artistiques et technologiques) afin d’en assurer la reprise en prenant en compte l’obsolescence programmée des technologies et l’intentionnalité des concepteurs ;</div>
</li>
<li class="level1"><div class="li"> les historiens : documentation des œuvres en prenant en compte le processus de création, les différentes variantes et la multiplicité des types de documents ;</div>
</li>
<li class="level1"><div class="li"> les responsables pédagogiques et les éditeurs : création de documentaires enrichis.</div>
</li>
</ul>

<p>
Rekall permet de documenter un spectacle à plusieurs moments de sa vie :
</p>
<ul>
<li class="level1"><div class="li"> pendant les répétitions (aide aux régisseurs et aux techniciens) ;</div>
</li>
<li class="level1"><div class="li"> au moment de la création (aide aux artistes pour la reprise du spectacle) ;</div>
</li>
<li class="level1"><div class="li"> après la création (aide aux historiens et aux éditeurs pour la réalisation de documentaires enrichis).</div>
</li>
</ul>

<p>
Le fonctionnement de Rekall repose sur les éléments qui décrivent ou retranscrivent une œuvre (une captation vidéo, une partition, un patch, un texte, un enregistrement sonore ou encore de simples notes). Ces éléments sont agrégés sur un axe du temps correspondant au déroulement de l’œuvre.
</p>

<p>
D’autres documents (notes, photographies, vidéos, textes, mails, commentaires, etc.) liés à la création ou simplement utiles à la compréhension gravitent autour de l’axe du temps. Présentés de façon ingénieuse, ils offrent un autre éclairage sur l’œuvre, donnent des précisions sur des aspects singuliers.
Il est possible d’afficher les documents recherchés selon différents filtres : par date, par type de document, par auteur, etc. Les liens entre les documents permettent d’établir des cartographies et des explorations multiples.
Toutes les personnes concernées par le projet collaborent au sein d’un même espace: ainsi, l’éclairagiste, le metteur en scène, le régisseur, le créateur vidéo et le scénographe partagent une plate-forme de travail commune.
</p>
<hr />

</div>

<h4 class="sectionedit5" id="informatisation-de-la-notation-chinoise-en-tablature-pour古琴-guqin">Informatisation de la notation chinoise en tablature pour古琴 guqin</h4>
<div class="level4">

<p>
<br/>

<a href="../../lib/exe/detail.php/evenements/2013-06-27-etude-notation1/guqin647b.html?id=evenements%3A2013-06-27-etude-notation1" class="media" title="evenements:2013-06-27-etude-notation1:guqin.jpg"><img src="../../lib/exe/fetch.php/evenements/2013-06-27-etude-notation1/guqinb1d8.jpg_%3b?w=160&amp;tok=d3c24e" class="mediaright" alt="" width="160" /></a>
<strong>Véronique Alexandre Journeau</strong>
</p>

<p>
L’écriture millénaire en tablature pour la cithare <em>qin</em> (古琴 <em>guqin</em>) est une notation si ingénieuse des paramètres du geste pour la production et la vie du son qu’elle reste présente même lorsqu’on a transcrit sur portée occidentale l’air ainsi noté. Parce qu’elle n’est pas constituée de caractères de la langue chinoise (et elle ne se prononce pas) mais procède par concaténation codifiée d’éléments de ces caractères linguistiques, un logiciel spécifique a été conçu sous la direction de ZHOU Changle 周昌乐, qui dirige le laboratoire Mind-Art &amp; Computation de l’Institut d’intelligence artificielle de l’université de Xiamen (Chine) pour produire de façon informatisée cette notation. C’est cependant une notation pour initiés et qui ne facilite pas l’analyse des airs de musique. Les perspectives seraient de pouvoir aussi transcrire, de façon complémentaire, les paramètres du son sur portée. Il est ici proposé de montrer le fonctionnement du logiciel et de poser les prémisses d’une transcription automatisée des hauteurs de son.
</p>
<hr />

</div>

<h5 class="sectionedit6" id="vers-des-partitions-interactives-pour-l-aide-a-la-composition-et-a-l-analyse-musicale">Vers des partitions interactives pour l’aide à la composition et à l’analyse musicale</h5>
<div class="level5">

<p>
<br/>

<a href="../../lib/exe/detail.php/evenements/2013-06-27-etude-notation1/inksplorer647b.html?id=evenements%3A2013-06-27-etude-notation1" class="media" title="evenements:2013-06-27-etude-notation1:inksplorer.png"><img src="../../lib/exe/fetch.php/evenements/2013-06-27-etude-notation1/inksplorer4dff.png_%3b?w=270&amp;tok=9e66ec" class="medialeft" alt="" width="270" /></a>
<strong>Mathieu Chailloux (IRCAM - UPMC), Jérémie Garcia (Université Paris Sud - IRCAM), Carlos Agon (IRCAM - UPMC)</strong>
</p>

<p>
Grâce aux technologies de papier interactif qui associent une trame presque invisible et un stylo doté d’une petite caméra, l&#039;ordinateur peut détecter ce qu&#039;écrit le compositeur. Ce lien « amont » entre le papier et l&#039;ordinateur est complété par un lien « aval » de l&#039;ordinateur vers le papier grâce à l&#039;impression, créant ainsi un cycle de production inédit. Des travaux précédents ont proposé plusieurs pistes pour l&#039;intégration de cette technologie avec des environnements de composition assistée par ordinateur. Nous explorons actuellement les possibilités offertes par des partitions interactives comme interfaces d’entrées pour l’ordinateur. En effet, grace aux formats actuels de description de partitions comme MusicXML3, il est possible de rendre tous les éléments graphiques interactifs. Le stylo peut ainsi être utilisé pour naviguer dans la partition, écouter des passages, modifier et ajouter des informations musicales. Une intégration dans le logiciel d&#039;édition de partitions Finale est prévue.
</p>

<p>
<em>Bibliographie:</em>
</p>
<ul>
<li class="level1"><div class="li"> “InkSplorer: Exploring Musical Ideas on Paper and Computer”, Garcia, J., Tsandilas, T., Mackay, W.E. and Agon, C. <em>New Interface for Musical Expression Conference (NIME)</em>, Oslo 2011.</div>
</li>
<li class="level1"><div class="li"> “Musink: composing music through augmented drawing.” Tsandilas, T., Letondal, C., and Mackay, W.E. <em>Proc. CHI’09</em>, 2009.</div>
</li>
</ul>
<hr />

</div>

<h4 class="sectionedit7" id="la-librairie-omxmulti-pour-openmusic-un-outil-d-aide-a-la-precomposition-musicale">La librairie OMXmulti pour OpenMusic un outil d&#039;aide à la précomposition musicale</h4>
<div class="level4">

<p>
<br/>

<strong>Yannick Chapuis</strong>
<a href="../../lib/exe/detail.php/evenements/2013-06-27-etude-notation1/omxmulti647b.html?id=evenements%3A2013-06-27-etude-notation1" class="media" title="evenements:2013-06-27-etude-notation1:omxmulti.jpg"><img src="../../lib/exe/fetch.php/evenements/2013-06-27-etude-notation1/omxmulti6847.jpg_%3b?w=280&amp;tok=2c0fdb" class="mediaright" alt="" width="280" /></a>
</p>

<p>
L&#039;objectif de la librairie <a href="http://sourceforge.net/projects/omxmulti/" class="urlextern" title="http://sourceforge.net/projects/omxmulti/" rel="nofollow">OMXmulti</a> est de mettre à disposition des utilisateurs un outil permettant d&#039;étendre les fonctionnalités d&#039;édition de la partition et de manipulation des objets musicaux dans OpenMusic.
Elle propose un objet unique <em>xmulti</em> qui peut être utilisé en remplacement des objets standard <em>chord-seq</em> et <em>multi-seq</em>.
</p>

<p>
De la même manière que les objets qu&#039;il remplace, l&#039;objet “xmulti” utilise la notation proportionnelle pour représenter les événements de la partition mais il met à disposition de l’utilisateur un certain nombre de nouvelles fonctionnalités intuitives :
</p>
<ul>
<li class="level1"><div class="li"> l’affichage de la partition a été amélioré (grille temporelle, nommage des portée/instruments, affichage intelligent des silences, des dynamiques et des durées, etc.) ;</div>
</li>
<li class="level1"><div class="li"> on a introduit de nouveaux moyens plus pratiques de saisie, de sélection et de déplacement des événements musicaux ;</div>
</li>
<li class="level1"><div class="li"> on dispose désormais d’une batterie de traitements musicaux complexes mais néanmoins courants qui sont directement utilisables sur les événements de la partition ; ces traitements peuvent être appliqués aux hauteurs, au rythme, aux dynamiques ou encore à plusieurs paramètres de façon conjointe (compression/expansion, répétition, division, rétrogradation, inversion, construction d&#039;échelles, génération pseudo-aléatoire, etc.).</div>
</li>
</ul>

<p>
En outre, l&#039;objet “xmulti” étend et facilite la manipulation des objets “extra” d&#039;OpenMusic : on peut désormais manipuler les liaisons et bien d&#039;autres annotations musicales courantes, qu&#039;elles soient individuelles (dynamiques, texte libre, articulations, ornementations, indications techniques, etc.) ou qu&#039;elles s&#039;appliquent à des phrases entières (crescendi, ligatures, tremoli, glissandi, etc.)
La plupart de ces opérations sont réalisables à la souris, par raccourci-clavier ou en utilisant les menus contextuels.
</p>

<p>
La librairie est disponible pour toutes les versions d&#039;OpenMusic comprises entre la 5.2.1 et la 6.5.1. Elle a été testée sur Windows 32 et 64 bits. Elle est développée par Yannick Chapuis et David Echevarria.
</p>
<hr />

</div>

<h4 class="sectionedit8" id="the-antescofo-musical-notationprogramming-realtime-musical-interactivity">The Antescofo musical notation: programming realtime musical interactivity</h4>
<div class="level4">

<p>
<br/>

<strong>Thomas Coffy (IRCAM -INRIA) et José Echeveste (IRCAM - UPMC)</strong>
<a href="../../lib/exe/detail.php/evenements/2013-06-27-etude-notation1/ascograph647b.html?id=evenements%3A2013-06-27-etude-notation1" class="media" title="evenements:2013-06-27-etude-notation1:ascograph.png"><img src="../../lib/exe/fetch.php/evenements/2013-06-27-etude-notation1/ascographc00f.png_%3b?w=300&amp;tok=a4e616" class="mediaright" alt="" width="300" /></a>
</p>

<p>
Antescofo~, developped at IRCAM, is a modular polyphonic Score Following system as well as a Synchronous Programming language for musical composition. The module allows for automatic recognition of music score position and tempo from a realtime audio Stream coming from performer(s), making it possible to synchronize an instrumental performance with computer realized elements. The synchronous language within Antescofo allows flexible writing of time and interaction in computer music.<br/>

The Antescofo musical notation embeds in the same score : the instrumental part, and the electronical part triggered by the instrumental one. Electronic music can then be written by composers in a natural textual way, or using a graphical editor specialized in the Antescofo musical notation : AscoGraph (editing of Break Point Functions, etc).<br/>

The presentation will include explanations on several key features of the language.
</p>
<hr />

</div>

<h4 class="sectionedit9" id="a-dictionary-based-approach-for-the-notation-of-musical-audio">A Dictionary-Based Approach for the Notation of Musical Audio</h4>
<div class="level4">

<p>
<br/>

<strong>Marlon Schumacher (IDMIL, DCS, CIRMMT - McGill University)</strong>
</p>

<p>
<a href="../../lib/exe/detail.php/evenements/2013-06-27-etude-notation1/om647b.html?id=evenements%3A2013-06-27-etude-notation1" class="media" title="evenements:2013-06-27-etude-notation1:om.jpg"><img src="../../lib/exe/fetch.php/evenements/2013-06-27-etude-notation1/omff3d.jpg_%3b?w=400&amp;tok=236bae" class="mediaright" alt="" width="400" /></a>
</p>

<p>
In this talk I will discuss a new approach for the notation of tape parts in the context of mixed music, i.e. the visualization of musical content in an audio signal. Traditionally, we seem to be stuck in a kind of dilemma typified by two extremes on a continuum: On the one end are signal-based notations, such as sonograms, waveforms, etc. -which however don’t provide much information about musical semantics. On the other end are symbolic notations, such as icons, characters, etc. -which in turn may not provide much information about the sonic details. Both aspects, however, are important for the interpretation of a musical work, in particular for contemporary music, which does not rely on common musical idioms.
</p>

<p>
I will present an approach attempting to combine aspects of both worlds, implemented as the library “OM-Pursuit” (for dictionary-based analysis/synthesis) within the computer-aided composition environment OpenMusic. This library allows the transcription of an audio signal based on a user-defined collection of smaller-scale sound files (so-called ‘atoms’). The individual atoms can be associated with arbitrary visual representations (symbolic, iconic, etc.). The user can then design simple programs to algorithmically arrange these visual elements on a 2D-canvas into a kind of cartographic map of the higher-level sonic content in the signal. I will discuss these concepts and show their use in the example of my recent piece for 2 pianists and tape “6 Fragments on 5’05” - 1 Act of cleaning a piano”. 
</p>

<p>
<a href="http://idmil.org/software/om-pursuit" class="urlextern" title="http://idmil.org/software/om-pursuit" rel="nofollow">http://idmil.org/software/om-pursuit</a>
</p>
<div class="divalign-right">
<p>
<font size=-2><i>Screenshot courtesy of http://www.editionfink.ch </i></font>
</p>
</div><!--divalign--><hr />

</div>

<h4 class="sectionedit10" id="l-acousmoscribe">L&#039;acousmoscribe</h4>
<div class="level4">

<p>
<a href="../../lib/exe/detail.php/evenements/2013-06-27-etude-notation1/acousmoscribe647b.html?id=evenements%3A2013-06-27-etude-notation1" class="media" title="evenements:2013-06-27-etude-notation1:acousmoscribe.png"><img src="../../lib/exe/fetch.php/evenements/2013-06-27-etude-notation1/acousmoscribed958.png_%3b?w=230&amp;tok=4896cd" class="mediaright" alt="" width="230" /></a>
<br/>

<strong>Jean-Louis Di Santo</strong>
</p>

<p>
L&#039;acousmoscribe est un système de notation symbolique du son suivant des critères perceptifs, issu de la notion d&#039;écoute réduite. Il emprunte sa philosophie à la linguistique qui permet de réaliser un grand nombre de combinaisons avec un petit nombre d&#039;éléments. L&#039;acousmoscribe autorise actuellement cinq milliards d&#039;occurences pour une description à la fois simple et précise du son. Le SCRIME travaille à l&#039;élaboration d&#039;un logiciel qui utilise ces données.
</p>

<p>
<a href="http://jean-louis.disanto.pagesperso-orange.fr/recherche.html" class="urlextern" title="http://jean-louis.disanto.pagesperso-orange.fr/recherche.html" rel="nofollow">http://jean-louis.disanto.pagesperso-orange.fr/recherche.html</a>
</p>
<hr />

</div>

<h4 class="sectionedit11" id="audiovisual-notation-transcription-case-studythe-tosso-variations">Audiovisual Notation &amp; Transcription. Case Study : The Tosso Variations</h4>
<div class="level4">

<p>
<br/>

<strong>Gabriel Shalom</strong>
<a href="../../lib/exe/detail.php/evenements/2013-06-27-etude-notation1/tosso-instrument-web647b.html?id=evenements%3A2013-06-27-etude-notation1" class="media" title="evenements:2013-06-27-etude-notation1:tosso-instrument-web.png"><img src="../../lib/exe/fetch.php/evenements/2013-06-27-etude-notation1/tosso-instrument-web5789.png_%3b?w=200&amp;tok=b9cf36" class="medialeft" alt="" width="200" /></a>
</p>

<p>
The process of composing audiovisual material can be aided by the creation of unique graphic notation systems. In this case study I will provide an insight into my working process in creating the audiovisual suite The Tosso Variations (2012). I will examine the role that graphic notation played in transcribing the improvised performances of my collaborator Shingo Inao playing his instrument Tosso - a hybrid electro-acoustic sensor instrument. The talk will conclude with the video screening of one of the five movements of the suite.
</p>

<p>
<a href="http://www.gabrielshalom.com/portfolio/the-tosso-variations/" class="urlextern" title="http://www.gabrielshalom.com/portfolio/the-tosso-variations/" rel="nofollow">http://www.gabrielshalom.com/portfolio/the-tosso-variations/</a>
</p>
<hr />

</div>

<h4 class="sectionedit12" id="notation-de-lʼespace-en-musique-electroacoustiquedu-geste-au-signe">Notation de lʼespace en musique électroacoustique : du geste au signe</h4>
<div class="level4">

<p>
<br/>

<strong>Bertrand Merlier (Université Lumière Lyon 2)</strong>
</p>

<p>
Cette intervention prend appui sur une analyse des fonctionnalités des divers dispositifs et logiciels permettant de travailler la spatialisation du son, sur une recherche portant sur les modes de perceptions de l’espace et enfin sur une étude approfondie des différents systèmes de notation. Au vu de l’ensemble de ces connaissances, une notation des activités de spatialisation reposant sur le paradigme de la notation de la musique classique occidentale est proposée. Divers exemples illustrent le bien-fondé et les aspects pratiques de cette proposition. La notation proposée est à la fois descriptive et prescriptive. C’est ainsi qu’une implémentation pratique basée sur la norme MIDI rend aussi envisageable un jeu instrumental de l’espace, la mise en place de processus algorithmiques en lien avec la structuration des idées, mais aussi l’usage de toute la panoplie de logiciels tels que séquenceur MIDI ou écriture de partition.
</p>

<p>
<a href="../../lib/exe/fetch.php/private/merliernotation2013a.html" class="media mediafile mf_pdf" title="private:merliernotation2013a.pdf (571.6 KB)">Lire l&#039;article complet</a>
</p>
<hr />

</div>

<h4 class="sectionedit13" id="iannix-09partition-graphique-interactive">Iannix 0.9 : Partition graphique interactive</h4>
<div class="level4">

<p>
<br/>

<strong>Guillaume Jacquemin, Matthieu Ranc (association Iannix)</strong>
<a href="../../lib/exe/detail.php/evenements/2013-06-27-etude-notation1/iannix647b.html?id=evenements%3A2013-06-27-etude-notation1" class="media" title="evenements:2013-06-27-etude-notation1:iannix.png"><img src="../../lib/exe/fetch.php/evenements/2013-06-27-etude-notation1/iannix2e90.png_%3b?w=300&amp;tok=44a2ae" class="mediaright" alt="" width="300" /></a>
</p>

<p>
IanniX est un séquenceur graphique open source, inspiré des travaux de Iannis Xenakis et destiné à la création numérique. 
À l’aide d’une palette d’objets fondamentaux que sont les triggers (événements), les courbes (trajectoires dans l’espace) et les curseurs (progression dans le temps), IanniX permet une représentation graphique du temps dans l’espace3D et assure un échange bidirectionnel vers plusieurs	protocoles de communication, dont l’Open Sound Control (supporté dans PureData, SuperCollider, CSound, MaxMSP, InScore…).
IanniX permet d’écrire ces partitions interactives du temps et de l’espace (quelqu’il soit, fréquences, hauteurs, filtres, paramètres de synthèse…) au travers :
</p>
<ul>
<li class="level1"><div class="li"> d’une interface graphique ; </div>
</li>
<li class="level1"><div class="li"> de messages réseaux (OSC, MIDI…) ; </div>
</li>
<li class="level1"><div class="li"> de code Javascript (en fichier ou en live coding) ; </div>
</li>
<li class="level1"><div class="li"> de capteurs (Arduino, Kinect…) ; </div>
</li>
<li class="level1"><div class="li"> ou en récursivité (partition en s’autocontrôlant).</div>
</li>
</ul>

<p>
À l’occasion de la sortie de <strong>IanniX 0.9</strong>, une série de nouveautés permettent d’exploiter de manière encore plus efficace les partitions graphiques de IanniX :
</p>
<ul>
<li class="level1"><div class="li"> Courbes : au-delà du dessin manuel ou génératif, les courbes peuvent maintenant être des équations paramétriques cartésiennes ou polaires, permettant ainsi d’introduire des représentations géométriques plus précises et rigoureuses ;</div>
</li>
<li class="level1"><div class="li"> Performance/scène : les partitions sont désormais facilement intégrables dans les outils de vidéastes grâce au protocole Syphon. La partition peut donc être montrée/video-mappée au public lors de concerts ;</div>
</li>
<li class="level1"><div class="li"> Messages : l’usage des messages réseaux (OSC, MIDI, Arduino…) pour manipuler les partitions est grandement facilité (aide contextuelle) et plus performant.</div>
</li>
</ul>

<p>
Pour ce Workshop Music Notation #1, nous proposons d’illustrer ces nouvelles formes d’écritures grâce à une démonstration pas-à-pas, en partant d’une partition vierge. La partition finale produite à l’issue des 15 min sera interactive (à l’aide de capteurs), graphique (usage des notations spécifiques à IanniX — triggers, courbes, curseurs) et récursive (« mise en résonnance » ,de l’écriture, de la partition).
</p>
<hr />

</div>

<h4 class="sectionedit14" id="ssmna-research-project-at-the-icst-zhdk">SSMN: A research project at the ICST (ZHdK)</h4>
<div class="level4">

<p>
<a href="../../lib/exe/detail.php/evenements/2013-06-27-etude-notation1/ssmn647b.html?id=evenements%3A2013-06-27-etude-notation1" class="media" title="evenements:2013-06-27-etude-notation1:ssmn.png"><img src="../../lib/exe/fetch.php/evenements/2013-06-27-etude-notation1/ssmne117.png_%3b?w=300&amp;tok=0e629c" class="mediaright" alt="" width="300" /></a>
<br/>

<strong>Emile Ellberger</strong>
</p>

<p>
The aim of SSMN is to open new ways of substantial integration of spatial relationships and processes in musical thinking as well as in composition, rehearsal and performance practice. For this purpose SSMN defines a typology of spatial movements and designs a library of symbols to represent them, able to be used in creative processes.
</p>

<p>
In order to validate its impact in the practice, an open source software tool that integrates this library within a common western musical notation context has been developed, allowing editing and acoustic feedback through a rendering engine. Composers are able to use and edit symbols describing spatialization in a notation program and immediately hear the results. Performers have full information of spatialization in the score and are able to hear the results from the beginning of the learning process. Since SSMN aims to meet the demands of the practice, composers and performers are involved in the project, writing and performing pieces using the SSMN tools. Their experience is the basis for the assessment of the project.
</p>

<p>
The basic research questions related to SSMN can be summarized as follows:
</p>

<p>
What could be the real impact (positive / negative) of a symbolic music notation of spatialization in composition, performance and analysis?
Is there a set of basic types of spatial movement?
What are the difficulties and the limits of representation of spatial movements and virtual spatial qualities in a, 2-dimensional graphic manner, and what kind of representation is more suitable?
SSMN argues that a deeper understanding of the nature and kinds of spatial movement helps composers to integrate spatialization into musical thinking in a substantial way especially if they have a proper tool, and that an adequate notation of spatial information has a positive impact in the way performers prepare for and act in a musical situation where spatialization plays an important role. If evidence of performance remains in notated form, it can become a subject of study and tradition. This may therefore influence also the sound diffusion practice, the interpretation research and the analysis of electroacoustic music.
</p>

<p>
The SSMN software tools may also be a model for successful interoperability between applications with different functions such as symbolic representation, music notation and audio rendering. In order to focus on spatialization, SSMN first concentrates on instrumental sound notated using CWMN and being spatialized by means of electroacoustics. This can be extended to other user cases in a further stage of research.
</p>

<p>
<br/>

<br/>

</p>
<hr />

<p>
<br/>

<strong>Organisation:</strong> Pierre Couprie (MINT-OMF, Université de Paris-Sorbonne), Dominique Fober (Grame), Yann Geslin (INA / GRM) Jean Bresson (IRCAM - UMR STMS). Groupe de travail AFIM “Les nouveaux espaces de la notation musicale” en collaboration avec le groupe Musicologie, Informatique et Nouvelles Technologies (MINT).
</p>

</div>

</div>
        </div>
        <div class="right-sidebar">
			<div class="menu">
		  		<ul>
</li>
</ul>
			</div>
          <div class="main_sidebar sidebar-box">
<ul>
<li class="level1"><div class="li"> <a href="../start.html" class="wikilink1" title="start"> Accueil</a></div>
</li>
<li class="level1"><div class="li"> <a href="../evenements.html" class="wikilink1" title="evenements"> Evénements</a></div>
</li>
<li class="level1"><div class="li"> <a href="http://tenor2015.tenor-conference.org/" class="urlextern" title="http://tenor2015.tenor-conference.org" rel="nofollow">Conférence 2015</a></div>
</li>
<li class="level1"><div class="li"> <a href="../liens.html" class="wikilink1" title="liens"> Liens</a></div>
</li>
<li class="level1"><div class="li"> <a href="../organisation.html" class="wikilink1" title="organisation"> Coordination</a></div>
</li>
<li class="level1"><div class="li"> <a href="http://listes.ircam.fr/sympa/info/music-notation" class="urlextern" title="http://listes.ircam.fr/sympa/info/music-notation" rel="nofollow">Mailing list</a></div>
</li>
</ul>


<ul>
<li class="level1"><div class="li"> <a href="../private/start.html" class="wikilink1" title="private:start">[private]</a></div>
</li>
</ul>

</div>
        </div>
      

   

    


     
    <div id="trail">
          </div>
    

</div>










    

    <div class="headerinc">
Dieses Dokuwiki verwendet ein von <a href="http://www.anymorphic.com/">Anymorphic Webdesign</a> erstelltes Thema.
</div>

<div align="center" class="footerinc">
  
  <a target="_blank" href="http://www.chimeric.de/" title="www.chimeric.de"><img src="../../lib/tpl/A_Centered_Perspective/images/button-chimeric-de.png" width="80" height="15" alt="www.chimeric.de" border="0" /></a>

  <a target="_blank" href="http://jigsaw.w3.org/css-validator/check/referer" title="Valid CSS"><img src="../../lib/tpl/A_Centered_Perspective/images/button-css.png" width="80" height="15" alt="Valid CSS" border="0" /></a>

  <a target="_blank" href="http://wiki.splitbrain.org/wiki:dokuwiki" title="Driven by DokuWiki"><img src="../../lib/tpl/A_Centered_Perspective/images/button-dw.png" width="80" height="15" alt="Driven by DokuWiki" border="0" /></a>

  <a target="_blank" href="http://www.firefox-browser.de/" title="do yourself a favour and use a real browser - get firefox"><img src="../../lib/tpl/A_Centered_Perspective/images/button-firefox.png" width="80" height="15" alt="do yourself a favour and use a real browser - get firefox!!" border="0" /></a>
  
  <a target="_blank" href="../../feed.php" title="Recent changes RSS feed"><img src="../../lib/tpl/A_Centered_Perspective/images/button-rss.png" width="80" height="15" alt="Recent changes RSS feed" border="0" /></a>

  <a target="_blank" href="http://validator.w3.org/check/referer" title="Valid XHTML 1.0"><img src="../../lib/tpl/A_Centered_Perspective/images/button-xhtml.png" width="80" height="15" alt="Valid XHTML 1.0" border="0" /></a>
</div>


<div class="no"><img src="../../lib/exe/indexer2c0e.gif?id=evenements%3A2013-06-27-etude-notation1&amp;1603091296" width="2" height="1" alt="" /></div>
</body>

<!-- Mirrored from notation.afim-asso.org/doku.php/evenements/2013-06-27-etude-notation1 by HTTrack Website Copier/3.x [XR&CO'2014], Mon, 19 Oct 2020 07:55:52 GMT -->
</html>
